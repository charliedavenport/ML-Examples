{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Perceptron model\n",
    "\n",
    "Run the model:\n",
    "\n",
    "$y = softmax\\left(\\mathbf{W}\\vec{x} + \\vec{b}\\right)$\n",
    "\n",
    "Train the model:\n",
    "\n",
    "$H_{y'}(y) = -\\sum_i y'_i \\log(y_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input node\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # shape = (instances, features)\n",
    "# var containing weights\n",
    "W = tf.Variable(tf.zeros([784, 10])) # (input features, classes)\n",
    "# biases\n",
    "b = tf.Variable(tf.zeros([10])) # 1 bias per class\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b) # softmax(Wx + b)\n",
    "\n",
    "with sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using High-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_worker_replicas': 0, '_task_type': None, '_task_id': 0, '_keep_checkpoint_max': 5, '_model_dir': '/tmp/mnist_clf', '_save_checkpoints_steps': None, '_tf_random_seed': None, '_environment': 'local', '_save_summary_steps': 100, '_session_config': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000028E00043DA0>, '_save_checkpoints_secs': 600, '_master': ''}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature X is not in features dictionary.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-5b2322015d84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     shuffle=True)\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# define testing input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             instructions)\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[0;32m    453\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks)\u001b[0m\n\u001b[0;32m    953\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m       \u001b[0mmodel_fn_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_train_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOSSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m       all_hooks.extend([\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_get_train_ops\u001b[1;34m(self, features, labels)\u001b[0m\n\u001b[0;32m   1160\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mModelFnOps\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m     \"\"\"\n\u001b[1;32m-> 1162\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_eval_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'model_dir'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_dir'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelFnOps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[1;34m(features, labels, mode, params, config)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mfeature_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             weight_collections=[parent_scope])\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden_units\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[1;34m(features, feature_columns, weight_collections, trainable)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mweight_collections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m             trainable=trainable)\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[0mnum_elements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_get_dense_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1649\u001b[0m     \u001b[1;31m# Feature has been already transformed. Return the intermediate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[1;31m# representation created by _transform_feature.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1651\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Transforming feature_column %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1460\u001b[1;33m     \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1461\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1462\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Column {} is not supported.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_transform_feature\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1618\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_transform_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1619\u001b[1;33m     \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1620\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1621\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_FeatureColumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1456\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature {} is not in features dictionary.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Feature X is not in features dictionary."
     ]
    }
   ],
   "source": [
    "feat_col = [tf.feature_column.numeric_column(key='X', shape=[784])]\n",
    "clf = tf.contrib.learn.DNNClassifier(hidden_units=[256, 256], # two hidden layers\n",
    "                                 feature_columns=feat_col,\n",
    "                                 n_classes=10,\n",
    "                                 model_dir='/tmp/mnist_clf')\n",
    "# define training input data\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(mnist.train.images)},\n",
    "    y=np.array(mnist.train.labels),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "# train the model\n",
    "clf.fit(input_fn=train_input_fn, steps=2000)\n",
    "# define testing input data\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(mnist.test.images)},\n",
    "    y=np.array(mnist.test.labels),\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "# nevermind... this is confusing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scikit-Learn\n",
    "\n",
    "because tensorflow is ~~fucking hard~~ adds a layer of abstraction on top of everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69  0  0  0  1  0  1  0  0  0]\n",
      " [ 0 66  1  2  0  0  0  0  1  3]\n",
      " [ 1  0 70  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 65  0  2  0  1  5  0]\n",
      " [ 0  0  0  0 70  0  1  0  0  3]\n",
      " [ 0  0  0  0  0 70  1  0  0  0]\n",
      " [ 0  1  0  0  0  0 73  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 70  2  0]\n",
      " [ 0  3  1  1  1  2  0  0 60  0]\n",
      " [ 0  0  0  1  0  2  0  0  0 68]]\n",
      "0.947148817803\n"
     ]
    }
   ],
   "source": [
    "import sklearn.neural_network\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1)) # shape is (n_samples, n_features)\n",
    "cutoff = int(n_samples * 0.6) # using 60% of data for training\n",
    "X_train = data[: cutoff] \n",
    "y_train = digits.target[: cutoff]\n",
    "# MLPs are sensitive to feature scaling - need to scale inputs in training set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.transform(X_train)\n",
    "\n",
    "X_test = data[cutoff :]\n",
    "y_test = digits.target[cutoff :]\n",
    "# also need to scale test data (scaler should only be fitted to training data!)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "clf = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(256,256,256), # 3 hidden layers\n",
    "                    activation='relu',\n",
    "                    solver='adam',\n",
    "                    batch_size='auto',\n",
    "                    max_iter=200,\n",
    "                    shuffle=True,\n",
    "                    epsilon=1e-8)  # hyperparam for adam solver; default value=1e-8\n",
    "clf.fit(X_train, y_train) # training in one line :-)\n",
    "y_pred = clf.predict(X_test)\n",
    "conf_mx = confusion_matrix(y_test, y_pred)\n",
    "score = clf.score(X_test, y_test)\n",
    "\n",
    "print(conf_mx)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
